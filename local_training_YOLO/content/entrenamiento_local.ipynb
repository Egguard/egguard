{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "\n",
        "# MODO DE USO (local o Colab)\n",
        "\n",
        "## Nuevo modelo desde cero\n",
        "\n",
        "1. **A√±ade el dataset**  \n",
        "    Coloca en la misma carpeta que este `.ipynb` el archivo `entrenamiento_modelo.zip` con la estructura:\n",
        "    ```\n",
        "    entrenamiento_modelo/\n",
        "    ‚îú‚îÄ‚îÄ train/\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îú‚îÄ‚îÄ valid/\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îú‚îÄ‚îÄ test/\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
        "    ‚îî‚îÄ‚îÄ data.yaml\n",
        "    ```\n",
        "\n",
        "2. **Ejecuta las celdas en orden:**\n",
        "    - Celda 0: Imports\n",
        "    - Celda 1: Configuraci√≥n Entorno (Muestra GPU local)\n",
        "    - Celda 2: Instala dependencias\n",
        "    - Celda 3: Prepara el dataset (desde un .zip)\n",
        "    - Celda 4: Configura el `data.yaml` (si no lo encuentra lo crea, modif√≠calo a mano para tu dataset)\n",
        "    - Celda 4.5: Diagn√≥stico de posibles problemas\n",
        "    - Celda 5: Visualizar algunas muestras (opcional)\n",
        "    - Celda 6: Sugerencias de configuraci√≥n del entrenamiento\n",
        "    - Celda 7: Entrenamiento con Transfer Learning  \n",
        "      **Ejemplo de ejecuci√≥n:**\n",
        "      ```python\n",
        "      modelo_entrenado, resultados = entrenar_detector_huevos(\n",
        "            model_size='n',  # Cambia seg√∫n tu preferencia: 'n', 's', 'm', 'l', 'x'\n",
        "            epochs=30,       # Ajusta seg√∫n tiempo disponible\n",
        "            batch_size=32,   # Ajusta seg√∫n GPU disponible\n",
        "            img_size=640,\n",
        "            patience=20\n",
        "      )\n",
        "      ```\n",
        "      > Modifica los par√°metros de \"# Data Augmentation espec√≠fica para huevos\" seg√∫n tu dataset.\n",
        "    - Celda 8: Evaluaci√≥n y m√©tricas del modelo reci√©n creado (Lo normal es que busque y coja autom√°ticamente el √∫ltimo modelo creado/mejorado)\n",
        "    - Celda 9: Prueba modelo creado con im√°genes nuevas (Lo normal es que busque y coja autom√°ticamente el √∫ltimo modelo creado/mejorado)\n",
        "    - Celda 10: Continuaci√≥n del entrenamiento (mejora y compara con el anterior, la comparaci√≥n a veces no funciona al mostrar la tabla)\n",
        "    - Celda 11: Consejos\n",
        "\n",
        "---\n",
        "\n",
        "## Mejorar modelo ya creado aqu√≠\n",
        "\n",
        "1. **Ejecuta las celdas en orden:**\n",
        "    - Celda Inicial: Imports\n",
        "    - Celda 1: Configuraci√≥n Entorno (Muestra GPU local)\n",
        "    - Celda 2: Instala dependencias\n",
        "    - Celda 4.5: Diagn√≥stico de posibles problemas\n",
        "    - Celda 6: Sugerencias de configuraci√≥n del entrenamiento (opcional)\n",
        "    - Celda 10: Continuaci√≥n del entrenamiento (mejora y compara con el anterior, la comparaci√≥n a veces no funciona al mostrar la tabla)\n",
        "\n",
        "2. **Extra:**  \n",
        "    - Celda 9: Prueba modelo mejorado con im√°genes nuevas (Lo normal es que busque y coja autom√°ticamente el √∫ltimo modelo creado/mejorado)\n",
        "\n",
        "---\n",
        "\n",
        "## SOLUCI√ìN DE ERRORES\n",
        "\n",
        "- Si al crear o continuar entrenando un modelo la GPU se queda sin memoria:\n",
        "  1. Borra la carpeta nueva de `trainX` en `runs/detect`.\n",
        "  2. En una terminal, ejecuta `nvidia-smi` para ver los procesos que usan GPU.\n",
        "  3. Mata el proceso con `kill NUMERO_PROCESO` (por ejemplo, `kill 11939`).\n",
        "  4. Reinicia el kernel si Visual Studio lo solicita.\n",
        "  5. Vuelve a ejecutar los pasos desde cero, **cambiando** el `batch_size` o `img_size` a valores menores.\n",
        "  6. Deja al menos 1GB de VRAM libre (por ejemplo, en una RTX 3060 de 6GB, no uses m√°s de 5GB por epoch).\n",
        "- Si al intentar evaluar un modelo te dice que no lo encuentra:\n",
        "  1. Vete a `runs/` y busca la √∫ltima `train/weights` y coge el `best.pt`\n",
        "  2. Pega el modelo en la carpeta que te pida\n",
        "  3. Lo normal es que coja autom√°ticamente el √∫ltimo modelo creado/mejorado\n",
        "\n",
        "---\n",
        "\n",
        "**Consejo:**  \n",
        "Evita usar bloques de c√≥digo para instrucciones largas, usa listas y encabezados para mayor claridad y mejor visualizaci√≥n en Jupyter/Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3o5MtMsUfaO"
      },
      "outputs": [],
      "source": [
        "# CELDA 0: IMPORTS NECESARIOS AL INICIO\n",
        "\n",
        "# YOLOv8 Transfer Learning - Detector de Huevos Brown/White\n",
        "# Optimizado para entrenamiento local con RTX 3060 Laptop 6GB\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPmL3SrzUfek",
        "outputId": "3d0fcadd-bd60-4239-cb8b-12aad5c50776"
      },
      "outputs": [],
      "source": [
        "# CELDA 1: Configuraci√≥n inicial y verificaci√≥n de GPU\n",
        "\n",
        "# Verificar GPU disponible\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üîß CONFIGURACI√ìN DEL ENTORNO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Verificar GPU\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"‚úÖ GPU disponible: {gpu_name}\")\n",
        "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"‚úÖ Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No hay GPU disponible - El entrenamiento ser√° muy lento\")\n",
        "\n",
        "print(f\"‚úÖ PyTorch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4vh6WIAUfjL",
        "outputId": "a5a84a17-19b0-4d06-c164-6d1f0f4d71f5"
      },
      "outputs": [],
      "source": [
        "# CELDA 2: Instalaci√≥n de dependencias\n",
        "\n",
        "# Instalar Ultralytics (YOLOv8)\n",
        "!pip install ultralytics roboflow\n",
        "\n",
        "# Imports necesarios\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "print(\"üì¶ Dependencias instaladas correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "JBQyIqtgUfny",
        "outputId": "17e893de-5697-4038-ee94-b465946457f3"
      },
      "outputs": [],
      "source": [
        "# CELDA 3: Preparar y descomprimir dataset\n",
        "\n",
        "print(\"üìÅ PREPARACI√ìN DEL DATASET\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Funci√≥n mejorada para subir y procesar dataset\n",
        "def subir_y_procesar_dataset():\n",
        "    \"\"\"Procesar dataset desde archivos subidos en Colab\"\"\"\n",
        "    print(\"üìÅ Buscando archivos ZIP subidos en Colab...\")\n",
        "\n",
        "    # Buscar archivos ZIP en el directorio actual\n",
        "    zip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\n",
        "\n",
        "    if not zip_files:\n",
        "        print(\"‚ùå No se encontraron archivos ZIP\")\n",
        "        print(\"üí° Aseg√∫rate de subir tu dataset ZIP usando el panel de archivos de Colab\")\n",
        "        return False\n",
        "\n",
        "    # Usar el primer ZIP encontrado\n",
        "    zip_name = zip_files[0]\n",
        "    print(f\"‚úÖ Archivo ZIP encontrado: {zip_name}\")\n",
        "\n",
        "    # Limpiar directorio anterior si existe\n",
        "    if os.path.exists('dataset'):\n",
        "        shutil.rmtree('dataset')\n",
        "\n",
        "    # Descomprimir\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(\"‚úÖ Dataset descomprimido\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al descomprimir: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Detectar estructura y reorganizar si es necesario\n",
        "    return detectar_y_reorganizar_estructura()\n",
        "\n",
        "\n",
        "def detectar_y_reorganizar_estructura():\n",
        "    \"\"\"Detecta la estructura del dataset y la reorganiza si es necesario\"\"\"\n",
        "    print(\"\\nüîç DETECTANDO ESTRUCTURA DEL DATASET...\")\n",
        "\n",
        "    # Buscar posibles ubicaciones del dataset\n",
        "    posibles_rutas = [\n",
        "        'entrenamiento_modelo',  # Si se subi√≥ la carpeta completa\n",
        "        '.',  # Si se descomprimi√≥ en la ra√≠z\n",
        "        'dataset'  # Si ya estaba en dataset\n",
        "    ]\n",
        "\n",
        "    dataset_path = None\n",
        "    for ruta in posibles_rutas:\n",
        "        if os.path.exists(ruta):\n",
        "            # Verificar si contiene train/valid\n",
        "            if (os.path.exists(os.path.join(ruta, 'train', 'images')) and\n",
        "                os.path.exists(os.path.join(ruta, 'valid', 'images'))):\n",
        "                dataset_path = ruta\n",
        "                print(f\"‚úÖ Dataset encontrado en: {dataset_path}\")\n",
        "                break\n",
        "\n",
        "    if not dataset_path:\n",
        "        print(\"‚ùå No se encontr√≥ estructura v√°lida del dataset\")\n",
        "        print(\"Explorando directorios disponibles...\")\n",
        "        for root, dirs, files in os.walk('.'):\n",
        "            if 'images' in dirs and 'labels' in dirs:\n",
        "                print(f\"Posible dataset en: {root}\")\n",
        "        return False\n",
        "\n",
        "    # Si el dataset no est√° en 'dataset/', moverlo ah√≠\n",
        "    if dataset_path != 'dataset':\n",
        "        if os.path.exists('dataset'):\n",
        "            shutil.rmtree('dataset')\n",
        "        shutil.move(dataset_path, 'dataset')\n",
        "        print(f\"üìÅ Dataset movido a 'dataset/'\")\n",
        "\n",
        "    return verificar_estructura_dataset()\n",
        "\n",
        "# Funci√≥n para verificar estructura del dataset\n",
        "def verificar_estructura_dataset():\n",
        "    \"\"\"Verificar y mostrar la estructura del dataset\"\"\"\n",
        "    base_path = Path('dataset')\n",
        "    required_structure = [\n",
        "        'train/images',\n",
        "        'train/labels',\n",
        "        'valid/images',\n",
        "        'valid/labels'\n",
        "    ]\n",
        "\n",
        "    print(\"\\nüîç VERIFICANDO ESTRUCTURA DEL DATASET:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    all_good = True\n",
        "    for item in required_structure:\n",
        "        full_path = base_path / item\n",
        "        if full_path.exists():\n",
        "            if full_path.is_dir():\n",
        "                # Contar archivos (excluyendo archivos ocultos)\n",
        "                files_list = [f for f in full_path.iterdir() if f.is_file() and not f.name.startswith('.')]\n",
        "                count = len(files_list)\n",
        "                print(f\"‚úÖ {item}: {count} archivos\")\n",
        "\n",
        "                # Mostrar algunos ejemplos\n",
        "                if count > 0:\n",
        "                    ejemplos = [f.name for f in files_list[:3]]\n",
        "                    print(f\"   Ejemplos: {', '.join(ejemplos)}\")\n",
        "            else:\n",
        "                print(f\"‚úÖ {item}: encontrado (archivo)\")\n",
        "        else:\n",
        "            print(f\"‚ùå {item}: NO encontrado\")\n",
        "            all_good = False\n",
        "\n",
        "    # Verificar data.yaml\n",
        "    yaml_files = list(Path('dataset').glob('*.yaml')) + list(Path('.').glob('data.yaml'))\n",
        "    if yaml_files:\n",
        "        print(f\"‚úÖ Archivo YAML encontrado: {yaml_files[0]}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se encontr√≥ data.yaml - se crear√° autom√°ticamente\")\n",
        "\n",
        "    if all_good:\n",
        "        print(\"\\nüéâ Estructura del dataset es correcta!\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Hay problemas con la estructura del dataset\")\n",
        "        print(\"Explorando toda la estructura disponible...\")\n",
        "        explorar_estructura_completa()\n",
        "\n",
        "    return all_good\n",
        "\n",
        "def explorar_estructura_completa():\n",
        "    \"\"\"Explorar toda la estructura de archivos para debug\"\"\"\n",
        "    print(\"\\nüîç EXPLORANDO ESTRUCTURA COMPLETA:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for root, dirs, files in os.walk('.'):\n",
        "        # Saltar directorios del sistema\n",
        "        if any(skip in root for skip in ['.config', '__pycache__', '.git', 'sample_data']):\n",
        "            continue\n",
        "\n",
        "        level = root.replace('.', '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "\n",
        "        # Mostrar solo algunos archivos para no saturar\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Solo primeros 5 archivos\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}... y {len(files) - 5} archivos m√°s\")\n",
        "\n",
        "# Ejecutar y procesar salida\n",
        "\n",
        "print(\"üöÄ PROCESANDO DATASET DESDE ARCHIVOS DE COLAB:\")\n",
        "print(\"1. Sube tu archivo ZIP usando el panel de archivos (üìÅ) en la barra lateral\")\n",
        "print(\"2. El archivo debe contener la estructura:\")\n",
        "print(\"entrenamiento_modelo/\")\n",
        "print(\"‚îú‚îÄ‚îÄ train/\")\n",
        "print(\"‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
        "print(\"‚îÇ   ‚îî‚îÄ‚îÄ labels/\")\n",
        "print(\"‚îú‚îÄ‚îÄ valid/\")\n",
        "print(\"‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
        "print(\"‚îÇ   ‚îî‚îÄ‚îÄ labels/\")\n",
        "print(\"‚îî‚îÄ‚îÄ data.yaml\")\n",
        "print()\n",
        "\n",
        "# Procesar autom√°ticamente si hay ZIP disponible\n",
        "if not subir_y_procesar_dataset():\n",
        "    print(\"‚ùå Error al procesar dataset\")\n",
        "    print(\"üí° Sube tu archivo ZIP y vuelve a ejecutar esta celda\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset procesado correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5c58CkiUfsD",
        "outputId": "67deb86f-0592-4a11-b365-4683cff36e95"
      },
      "outputs": [],
      "source": [
        "# CELDA 4: Configuraci√≥n del data.yaml\n",
        "\n",
        "def crear_data_yaml_dinamico():\n",
        "    \"\"\"Crear data.yaml con rutas correctas detectadas autom√°ticamente\"\"\"\n",
        "\n",
        "    # Verificar que existe la estructura del dataset\n",
        "    if not os.path.exists('dataset/train/images'):\n",
        "        print(\"‚ùå No se encuentra dataset/train/images\")\n",
        "        return False\n",
        "\n",
        "    # Contar im√°genes para verificar\n",
        "    train_images = len([f for f in Path('dataset/train/images').iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])\n",
        "    val_images = len([f for f in Path('dataset/valid/images').iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])\n",
        "\n",
        "    print(f\"üìä Im√°genes encontradas:\")\n",
        "    print(f\"  Entrenamiento: {train_images}\")\n",
        "    print(f\"  Validaci√≥n: {val_images}\")\n",
        "\n",
        "    # Crear data.yaml con rutas absolutas para evitar problemas\n",
        "    yaml_content = f\"\"\"# Dataset configuration for YOLOv8 Egg Detection\n",
        "# Paths - usando rutas absolutas para Colab\n",
        "\n",
        "train: /content/dataset/train/images\n",
        "val: /content/dataset/valid/images\n",
        "\n",
        "nc: 2\n",
        "names: ['Brown Egg', 'White Egg']\n",
        "\n",
        "# Dataset info\n",
        "roboflow:\n",
        "  workspace: data-science-4tmzt\n",
        "  project: egg-segmentation-in-poultry-industry-based-on-color-pxcll\n",
        "  version: 2\n",
        "  license: CC BY 4.0\n",
        "\"\"\"\n",
        "\n",
        "    with open('data.yaml', 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(\"‚úÖ data.yaml creado con rutas absolutas\")\n",
        "\n",
        "    # Verificar que las rutas existen\n",
        "    train_path = Path('/content/dataset/train/images')\n",
        "    val_path = Path('/content/dataset/valid/images')\n",
        "\n",
        "    if train_path.exists() and val_path.exists():\n",
        "        print(\"‚úÖ Rutas verificadas correctamente\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"‚ùå Error: Las rutas en data.yaml no existen\")\n",
        "        return False\n",
        "\n",
        "# Crear data.yaml\n",
        "if not crear_data_yaml_dinamico():\n",
        "    print(\"‚ùå Error al crear data.yaml\")\n",
        "    print(\"Creando data.yaml con rutas relativas como respaldo...\")\n",
        "\n",
        "    yaml_content_backup = \"\"\"# Dataset configuration - rutas relativas\n",
        "train: dataset/train/images\n",
        "val: dataset/valid/images\n",
        "\n",
        "nc: 2\n",
        "names: ['Brown Egg', 'White Egg']\n",
        "\"\"\"\n",
        "\n",
        "    with open('data.yaml', 'w') as f:\n",
        "        f.write(yaml_content_backup)\n",
        "\n",
        "    print(\"‚úÖ data.yaml de respaldo creado\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qgpev5WUfws",
        "outputId": "7442ddf5-31c0-4a24-bf42-2ac6c65c5270"
      },
      "outputs": [],
      "source": [
        "# CELDA 4.5: Diagn√≥stico y soluci√≥n de problemas\n",
        "\n",
        "def diagnosticar_dataset():\n",
        "    \"\"\"Diagn√≥stico completo del dataset para resolver problemas\"\"\"\n",
        "    print(\"üîç DIAGN√ìSTICO COMPLETO DEL DATASET\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. Verificar estructura actual\n",
        "    print(\"1. ESTRUCTURA ACTUAL:\")\n",
        "    current_dirs = []\n",
        "    for item in os.listdir('.'):\n",
        "        if os.path.isdir(item) and not item.startswith('.'):\n",
        "            current_dirs.append(item)\n",
        "    print(f\"Directorios disponibles: {current_dirs}\")\n",
        "\n",
        "    # 2. Buscar directorios con im√°genes\n",
        "    print(\"\\n2. BUSCANDO DIRECTORIOS CON IM√ÅGENES:\")\n",
        "    image_dirs = []\n",
        "    for root, dirs, files in os.walk('.'):\n",
        "        if any(f.lower().endswith(('.jpg', '.jpeg', '.png')) for f in files):\n",
        "            img_count = len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            if img_count > 0:\n",
        "                image_dirs.append((root, img_count))\n",
        "                print(f\"  {root}: {img_count} im√°genes\")\n",
        "\n",
        "    # 3. Buscar directorios con labels\n",
        "    print(\"\\n3. BUSCANDO DIRECTORIOS CON LABELS:\")\n",
        "    label_dirs = []\n",
        "    for root, dirs, files in os.walk('.'):\n",
        "        if any(f.lower().endswith('.txt') for f in files):\n",
        "            txt_count = len([f for f in files if f.lower().endswith('.txt')])\n",
        "            if txt_count > 0:\n",
        "                label_dirs.append((root, txt_count))\n",
        "                print(f\"  {root}: {txt_count} archivos .txt\")\n",
        "\n",
        "    # 4. Intentar reorganizar autom√°ticamente\n",
        "    print(\"\\n4. REORGANIZACI√ìN AUTOM√ÅTICA:\")\n",
        "    return reorganizar_automaticamente(image_dirs, label_dirs)\n",
        "\n",
        "def reorganizar_automaticamente(image_dirs, label_dirs):\n",
        "    \"\"\"Reorganizar autom√°ticamente la estructura del dataset\"\"\"\n",
        "\n",
        "    # Limpiar dataset anterior\n",
        "    if os.path.exists('dataset'):\n",
        "        shutil.rmtree('dataset')\n",
        "    os.makedirs('dataset', exist_ok=True)\n",
        "\n",
        "    # Buscar directorios train y valid\n",
        "    train_img_dir = None\n",
        "    train_lbl_dir = None\n",
        "    valid_img_dir = None\n",
        "    valid_lbl_dir = None\n",
        "\n",
        "    # Identificar directorios por nombre\n",
        "    for img_dir, count in image_dirs:\n",
        "        if 'train' in img_dir.lower() and 'image' in img_dir.lower():\n",
        "            train_img_dir = img_dir\n",
        "            print(f\"‚úÖ Train images encontrado: {img_dir} ({count} im√°genes)\")\n",
        "        elif 'valid' in img_dir.lower() and 'image' in img_dir.lower():\n",
        "            valid_img_dir = img_dir\n",
        "            print(f\"‚úÖ Valid images encontrado: {img_dir} ({count} im√°genes)\")\n",
        "\n",
        "    for lbl_dir, count in label_dirs:\n",
        "        if 'train' in lbl_dir.lower() and 'label' in lbl_dir.lower():\n",
        "            train_lbl_dir = lbl_dir\n",
        "            print(f\"‚úÖ Train labels encontrado: {lbl_dir} ({count} labels)\")\n",
        "        elif 'valid' in lbl_dir.lower() and 'label' in lbl_dir.lower():\n",
        "            valid_lbl_dir = lbl_dir\n",
        "            print(f\"‚úÖ Valid labels encontrado: {lbl_dir} ({count} labels)\")\n",
        "\n",
        "    # Verificar que encontramos todo\n",
        "    if not all([train_img_dir, train_lbl_dir, valid_img_dir, valid_lbl_dir]):\n",
        "        print(\"‚ùå No se pudieron encontrar todos los directorios necesarios\")\n",
        "        print(f\"Train images: {train_img_dir}\")\n",
        "        print(f\"Train labels: {train_lbl_dir}\")\n",
        "        print(f\"Valid images: {valid_img_dir}\")\n",
        "        print(f\"Valid labels: {valid_lbl_dir}\")\n",
        "        return False\n",
        "\n",
        "    # Crear estructura correcta\n",
        "    os.makedirs('dataset/train/images', exist_ok=True)\n",
        "    os.makedirs('dataset/train/labels', exist_ok=True)\n",
        "    os.makedirs('dataset/valid/images', exist_ok=True)\n",
        "    os.makedirs('dataset/valid/labels', exist_ok=True)\n",
        "\n",
        "    # Copiar archivos\n",
        "    try:\n",
        "        # Copiar im√°genes de entrenamiento\n",
        "        for file in Path(train_img_dir).iterdir():\n",
        "            if file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                shutil.copy2(file, 'dataset/train/images/')\n",
        "\n",
        "        # Copiar labels de entrenamiento\n",
        "        for file in Path(train_lbl_dir).iterdir():\n",
        "            if file.suffix.lower() == '.txt':\n",
        "                shutil.copy2(file, 'dataset/train/labels/')\n",
        "\n",
        "        # Copiar im√°genes de validaci√≥n\n",
        "        for file in Path(valid_img_dir).iterdir():\n",
        "            if file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                shutil.copy2(file, 'dataset/valid/images/')\n",
        "\n",
        "        # Copiar labels de validaci√≥n\n",
        "        for file in Path(valid_lbl_dir).iterdir():\n",
        "            if file.suffix.lower() == '.txt':\n",
        "                shutil.copy2(file, 'dataset/valid/labels/')\n",
        "\n",
        "        print(\"‚úÖ Archivos copiados exitosamente\")\n",
        "        return verificar_estructura_dataset()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al copiar archivos: {e}\")\n",
        "        return False\n",
        "\n",
        "# Ejecutar diagn√≥stico si es necesario\n",
        "print(\"üîß DIAGN√ìSTICO AUTOM√ÅTICO\")\n",
        "print(\"Ejecutando diagn√≥stico para resolver problemas de estructura...\")\n",
        "if diagnosticar_dataset():\n",
        "    print(\"‚úÖ Dataset reorganizado correctamente\")\n",
        "else:\n",
        "    print(\"‚ùå No se pudo reorganizar autom√°ticamente\")\n",
        "    print(\"Por favor, verifica manualmente la estructura de tu ZIP\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvo8haJxUf1Q"
      },
      "outputs": [],
      "source": [
        "# CELDA 5: Visualizaci√≥n de muestras del dataset\n",
        "\n",
        "\n",
        "def visualizar_muestras():\n",
        "    \"\"\"Visualizar algunas im√°genes del dataset con sus labels\"\"\"\n",
        "    import random\n",
        "\n",
        "    train_images = list(Path('dataset/train/images').glob('*.jpg'))\n",
        "    if not train_images:\n",
        "        train_images = list(Path('dataset/train/images').glob('*.png'))\n",
        "\n",
        "    if len(train_images) == 0:\n",
        "        print(\"‚ùå No se encontraron im√°genes de entrenamiento\")\n",
        "        return\n",
        "\n",
        "    # Seleccionar 4 im√°genes aleatorias\n",
        "    sample_images = random.sample(train_images, min(4, len(train_images)))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, img_path in enumerate(sample_images):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "\n",
        "        # Cargar imagen\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Cargar labels si existen\n",
        "        label_path = img_path.parent.parent / 'labels' / f\"{img_path.stem}.txt\"\n",
        "\n",
        "        if label_path.exists():\n",
        "            with open(label_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    x_center = float(parts[1]) * w\n",
        "                    y_center = float(parts[2]) * h\n",
        "                    width = float(parts[3]) * w\n",
        "                    height = float(parts[4]) * h\n",
        "\n",
        "                    # Dibujar bounding box\n",
        "                    x1 = int(x_center - width/2)\n",
        "                    y1 = int(y_center - height/2)\n",
        "                    x2 = int(x_center + width/2)\n",
        "                    y2 = int(y_center + height/2)\n",
        "\n",
        "                    color = (255, 0, 0) if class_id == 0 else (0, 255, 0)  # Rojo para Brown, Verde para White\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                    label = \"Brown Egg\" if class_id == 0 else \"White Egg\"\n",
        "                    cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Muestra {i+1}: {img_path.name}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Ejecutar visualizaci√≥n (comentar si no quieres ejecutar)\n",
        "    visualizar_muestras()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMtPPJ-kUf5u",
        "outputId": "caee1a40-652a-42b1-a43b-57cd5f2a9694"
      },
      "outputs": [],
      "source": [
        "# CELDA 6: Configuraci√≥n de entrenamiento optimizada\n",
        "\n",
        "import torch\n",
        "\n",
        "# Configuraci√≥n de modelos disponibles\n",
        "MODELOS_YOLO = {\n",
        "    'n': 'yolov8n.pt',  # Nano - 3.2M params - Muy r√°pido\n",
        "    's': 'yolov8s.pt',  # Small - 11.2M params - Balance √≥ptimo\n",
        "    'm': 'yolov8m.pt',  # Medium - 25.9M params - M√°s preciso\n",
        "    'l': 'yolov8l.pt',  # Large - 43.7M params - Muy preciso\n",
        "    'x': 'yolov8x.pt'   # Extra Large - 68.2M params - M√°xima precisi√≥n\n",
        "}\n",
        "\n",
        "def recomendar_configuracion():\n",
        "    \"\"\"Configuraci√≥n optimizada seg√∫n memoria GPU detectada\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        gpu_memory = props.total_memory / 1e9\n",
        "        gpu_name = props.name.lower()\n",
        "\n",
        "        # Ajuste espec√≠fico para RTX 3060 Laptop 6GB\n",
        "        if \"3060\" in gpu_name and \"laptop\" in gpu_name and gpu_memory <= 6.1:\n",
        "            return {\n",
        "                'model': MODELOS_YOLO['n'],\n",
        "                'epochs': 30,\n",
        "                'batch': 34,  # Confirmado que usa ~5.2GB/6GB\n",
        "                'imgsz': 640,\n",
        "                'patience': 20\n",
        "            }\n",
        "        elif gpu_memory >= 15:  # T4 o superior\n",
        "            return {\n",
        "                'model': MODELOS_YOLO['n'],\n",
        "                'epochs': 50,\n",
        "                'batch': 64,\n",
        "                'imgsz': 640,\n",
        "                'patience': 20\n",
        "            }\n",
        "        elif gpu_memory >= 8:  # GPU media\n",
        "            return {\n",
        "                'model': MODELOS_YOLO['n'],\n",
        "                'epochs': 20,\n",
        "                'batch': 32,\n",
        "                'imgsz': 512,\n",
        "                'patience': 10\n",
        "            }\n",
        "        else:  # GPU b√°sica\n",
        "            return {\n",
        "                'model': MODELOS_YOLO['n'],\n",
        "                'epochs': 20,\n",
        "                'batch': 16,\n",
        "                'imgsz': 416,\n",
        "                'patience': 5\n",
        "            }\n",
        "    else:  # CPU\n",
        "        return {\n",
        "            'model': MODELOS_YOLO['n'],\n",
        "            'epochs': 5,\n",
        "            'batch': 4,\n",
        "            'imgsz': 320,\n",
        "            'patience': 2\n",
        "        }\n",
        "\n",
        "# Ejecutar configuraci√≥n recomendada\n",
        "config_recomendada = recomendar_configuracion()\n",
        "print(\"üéØ CONFIGURACI√ìN RECOMENDADA:\")\n",
        "print(f\"Modelo: {config_recomendada['model']}\")\n",
        "print(f\"√âpocas: {config_recomendada['epochs']}\")\n",
        "print(f\"Batch size: {config_recomendada['batch']}\")\n",
        "print(f\"Tama√±o imagen: {config_recomendada['imgsz']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od4uMZekUf-Y",
        "outputId": "78531cf8-a3cd-473d-ab01-d07e52b03852"
      },
      "outputs": [],
      "source": [
        "# CELDA 7: Entrenamiento con Transfer Learning\n",
        "\n",
        "\n",
        "def entrenar_detector_huevos(\n",
        "    model_size='s',\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    img_size=416,\n",
        "    patience=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Entrenamiento optimizado con transfer learning para detecci√≥n de huevos\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ INICIANDO ENTRENAMIENTO CON TRANSFER LEARNING\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    model_path = MODELOS_YOLO[model_size]\n",
        "    print(f\"üì¶ Cargando modelo base: {model_path}\")\n",
        "\n",
        "    # Cargar modelo preentrenado\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Configuraci√≥n de entrenamiento optimizada para huevos\n",
        "    training_args = {\n",
        "        # Dataset\n",
        "        'data': 'data.yaml',\n",
        "        'epochs': epochs,\n",
        "        'imgsz': img_size,\n",
        "        'batch': batch_size,\n",
        "\n",
        "        # Output\n",
        "        'name': f'detector_huevos_{model_size}',\n",
        "        'project': 'runs/detect',\n",
        "        'save_period': 5,  # Guardar cada 5 √©pocas\n",
        "\n",
        "        # Transfer Learning - Learning rates conservadores\n",
        "        'lr0': 0.01,        # LR inicial bajo para transfer learning\n",
        "        'lrf': 0.01,        # LR final\n",
        "        'momentum': 0.937,\n",
        "        'weight_decay': 0.0005,\n",
        "        'warmup_epochs': 3,\n",
        "\n",
        "        # Data Augmentation espec√≠fica para huevos\n",
        "        'hsv_h': 0.015,     # Variaci√≥n de matiz muy ligera\n",
        "        'hsv_s': 0.7,       # Saturaci√≥n importante (brown vs white)\n",
        "        'hsv_v': 0.4,       # Variaci√≥n de brillo\n",
        "        'degrees': 15.0,    # Rotaci√≥n ligera\n",
        "        'translate': 0.1,   # Translaci√≥n\n",
        "        'scale': 0.5,       # Variaci√≥n de escala\n",
        "        'shear': 0.0,       # Sin sesgo (huevos sim√©tricos)\n",
        "        'perspective': 0.0, # Sin perspectiva extrema\n",
        "        'flipud': 0.0,      # Sin volteo vertical\n",
        "        'fliplr': 0.5,      # Volteo horizontal OK\n",
        "        'mosaic': 1.0,      # Mosaic augmentation\n",
        "        'mixup': 0.0,       # Sin mixup (confunde colores)\n",
        "        'copy_paste': 0.0,  # Sin copy-paste\n",
        "\n",
        "        # Optimizaci√≥n\n",
        "        'optimizer': 'SGD',  # SGD funciona bien con transfer learning\n",
        "        'patience': patience,\n",
        "        'dropout': 0.0,\n",
        "\n",
        "        # Hardware\n",
        "        'device': 0 if torch.cuda.is_available() else 'cpu',\n",
        "        'workers': 2,  # Reducido para Colab\n",
        "\n",
        "        # Monitoreo\n",
        "        'verbose': True,\n",
        "        'plots': True,\n",
        "        'save': True,\n",
        "        'val': True,\n",
        "\n",
        "        # Configuraciones adicionales para Colab\n",
        "        'cache': False,  # No usar cache para ahorrar memoria\n",
        "        'amp': True,     # Automatic Mixed Precision para T4\n",
        "    }\n",
        "\n",
        "    print(\"‚öôÔ∏è Configuraci√≥n de entrenamiento:\")\n",
        "    for key, value in training_args.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nüî• Iniciando entrenamiento...\")\n",
        "        results = model.train(**training_args)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üéâ ENTRENAMIENTO COMPLETADO EXITOSAMENTE\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return model, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error durante el entrenamiento: {e}\")\n",
        "        print(\"\\nüîÑ Intentando con configuraci√≥n simplificada...\")\n",
        "\n",
        "        # Configuraci√≥n simplificada\n",
        "        simple_args = {\n",
        "            'data': 'data.yaml',\n",
        "            'epochs': epochs,\n",
        "            'imgsz': img_size,\n",
        "            'batch': max(batch_size//2, 4),  # Reducir batch si hay problemas\n",
        "            'name': f'detector_huevos_{model_size}_simple',\n",
        "            'lr0': 0.01,\n",
        "            'patience': patience,\n",
        "            'device': 0 if torch.cuda.is_available() else 'cpu',\n",
        "            'amp': False,  # Desactivar AMP si hay problemas\n",
        "        }\n",
        "\n",
        "        results = model.train(**simple_args)\n",
        "        return model, results\n",
        "\n",
        "# Ejecutar entrenamiento\n",
        "modelo_entrenado, resultados = entrenar_detector_huevos(\n",
        "    model_size='n',  # Cambiar seg√∫n tu preferencia: 'n', 's', 'm', 'l', 'x'\n",
        "    epochs=30,      # Ajustar seg√∫n tiempo disponible\n",
        "    batch_size=32,   # Ajustar seg√∫n GPU disponible\n",
        "    img_size=640,\n",
        "    patience=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xgop-zPVUgC0",
        "outputId": "3defcad2-3230-407f-deaa-2d28b730a04b"
      },
      "outputs": [],
      "source": [
        "# CELDA 8: Evaluaci√≥n y m√©tricas\n",
        "\n",
        "def encontrar_mejor_modelo():\n",
        "    \"\"\"Buscar el modelo best.pt en todas las carpetas posibles\"\"\"\n",
        "    runs_dir = Path('runs/detect')\n",
        "    posibles_rutas = []\n",
        "    \n",
        "    if runs_dir.exists():\n",
        "        # Buscar en todas las subcarpetas de runs/detect\n",
        "        for carpeta in runs_dir.iterdir():\n",
        "            if carpeta.is_dir():\n",
        "                # Buscar best.pt en weights/\n",
        "                ruta_weights = carpeta / 'weights' / 'best.pt'\n",
        "                if ruta_weights.exists():\n",
        "                    posibles_rutas.append((ruta_weights, carpeta.stat().st_mtime))\n",
        "                \n",
        "                # Tambi√©n buscar directamente en la carpeta\n",
        "                ruta_directa = carpeta / 'best.pt'\n",
        "                if ruta_directa.exists():\n",
        "                    posibles_rutas.append((ruta_directa, carpeta.stat().st_mtime))\n",
        "    \n",
        "    if posibles_rutas:\n",
        "        # Ordenar por fecha de modificaci√≥n (m√°s reciente primero)\n",
        "        posibles_rutas.sort(key=lambda x: x[1], reverse=True)\n",
        "        return posibles_rutas[0][0]\n",
        "    \n",
        "    return None\n",
        "\n",
        "def evaluar_modelo():\n",
        "    \"\"\"Evaluar el modelo entrenado\"\"\"\n",
        "    print(\"üìä EVALUACI√ìN DEL MODELO\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Buscar el modelo\n",
        "    best_model_path = encontrar_mejor_modelo()\n",
        "    \n",
        "    if best_model_path is None:\n",
        "        print(\"‚ùå No se encuentra ning√∫n modelo best.pt\")\n",
        "        print(\"üîç Verificando carpetas disponibles...\")\n",
        "        runs_dir = Path('runs/detect')\n",
        "        if runs_dir.exists():\n",
        "            for carpeta in runs_dir.iterdir():\n",
        "                if carpeta.is_dir():\n",
        "                    print(f\"  üìÅ {carpeta.name}/\")\n",
        "                    weights_dir = carpeta / 'weights'\n",
        "                    if weights_dir.exists():\n",
        "                        archivos = list(weights_dir.glob('*.pt'))\n",
        "                        if archivos:\n",
        "                            print(f\"    ‚îî‚îÄ‚îÄ weights/: {[f.name for f in archivos]}\")\n",
        "                        else:\n",
        "                            print(f\"    ‚îî‚îÄ‚îÄ weights/: (vac√≠a)\")\n",
        "                    else:\n",
        "                        print(f\"    ‚îî‚îÄ‚îÄ No hay carpeta weights/\")\n",
        "        return None, None\n",
        "    \n",
        "    print(f\"‚úÖ Modelo encontrado: {best_model_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Cargar modelo\n",
        "        model = YOLO(str(best_model_path))\n",
        "        \n",
        "        # Validaci√≥n\n",
        "        print(\"üîÑ Ejecutando validaci√≥n...\")\n",
        "        metrics = model.val()\n",
        "        \n",
        "        print(f\"\\nüìà M√âTRICAS FINALES:\")\n",
        "        print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
        "        print(f\"mAP50-95: {metrics.box.map:.3f}\")\n",
        "        print(f\"Precision: {metrics.box.mp:.3f}\")\n",
        "        print(f\"Recall: {metrics.box.mr:.3f}\")\n",
        "        \n",
        "        # Mostrar curvas de entrenamiento\n",
        "        carpeta_modelo = best_model_path.parent.parent\n",
        "        results_png = carpeta_modelo / 'results.png'\n",
        "        if results_png.exists():\n",
        "            print(f\"\\nüìä Curvas de entrenamiento:\")\n",
        "            display(Image(str(results_png)))\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  No se encontr√≥ results.png en {carpeta_modelo}\")\n",
        "            \n",
        "        return model, metrics\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el modelo: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Evaluar modelo\n",
        "modelo_final, metricas = evaluar_modelo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v0hTXZvWUgIC",
        "outputId": "a6e598e8-b623-4029-f5ba-389a73c3115c"
      },
      "outputs": [],
      "source": [
        "# CELDA 9: Pruebas con im√°genes (CORREGIDA) - CON GUARDADO\n",
        "\n",
        "def probar_modelo_con_muestras():\n",
        "    \"\"\"Probar el modelo con im√°genes del dataset y guardar resultados\"\"\"\n",
        "    print(\"üß™ PROBANDO MODELO CON MUESTRAS\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Crear carpeta para guardar resultados\n",
        "    resultados_dir = Path('resultados_pruebas')\n",
        "    resultados_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    # Buscar modelo\n",
        "    best_model_path = encontrar_mejor_modelo()\n",
        "    \n",
        "    if best_model_path is None:\n",
        "        print(\"‚ùå No se encuentra el modelo best.pt\")\n",
        "        return\n",
        "    \n",
        "    print(f\"‚úÖ Usando modelo: {best_model_path}\")\n",
        "    \n",
        "    try:\n",
        "        model = YOLO(str(best_model_path))\n",
        "        \n",
        "        # Buscar im√°genes de validaci√≥n en diferentes ubicaciones posibles\n",
        "        posibles_dirs = [\n",
        "            Path('dataset/valid/images'),\n",
        "            Path('dataset/val/images'),\n",
        "            Path('valid/images'),\n",
        "            Path('val/images')\n",
        "        ]\n",
        "        \n",
        "        val_images = []\n",
        "        for dir_path in posibles_dirs:\n",
        "            if dir_path.exists():\n",
        "                # Buscar jpg, png, jpeg\n",
        "                for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
        "                    val_images.extend(list(dir_path.glob(ext)))\n",
        "                if val_images:\n",
        "                    print(f\"üìÅ Im√°genes encontradas en: {dir_path}\")\n",
        "                    break\n",
        "        \n",
        "        if not val_images:\n",
        "            print(\"‚ùå No se encontraron im√°genes de validaci√≥n\")\n",
        "            print(\"üîç Verificando directorios disponibles...\")\n",
        "            for dir_path in posibles_dirs:\n",
        "                if dir_path.exists():\n",
        "                    archivos = list(dir_path.iterdir())\n",
        "                    print(f\"  üìÅ {dir_path}: {len(archivos)} archivos\")\n",
        "            return\n",
        "        \n",
        "        print(f\"üì∏ Total de im√°genes disponibles: {len(val_images)}\")\n",
        "        \n",
        "        # Probar con 6 im√°genes aleatorias\n",
        "        import random\n",
        "        from datetime import datetime\n",
        "        \n",
        "        num_muestras = min(6, len(val_images))\n",
        "        sample_images = random.sample(val_images, num_muestras)\n",
        "        \n",
        "        # Crear nombre √∫nico para esta sesi√≥n\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        \n",
        "        plt.figure(figsize=(20, 15))\n",
        "        \n",
        "        # Lista para guardar informaci√≥n de detecciones\n",
        "        detecciones_info = []\n",
        "        \n",
        "        for i, img_path in enumerate(sample_images):\n",
        "            plt.subplot(2, 3, i+1)\n",
        "            \n",
        "            try:\n",
        "                # Hacer predicci√≥n\n",
        "                results = model(str(img_path), conf=0.25, iou=0.45)\n",
        "                \n",
        "                # Visualizar resultado\n",
        "                annotated = results[0].plot()\n",
        "                annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
        "                plt.imshow(annotated_rgb)\n",
        "                plt.title(f\"Predicci√≥n: {img_path.name}\")\n",
        "                plt.axis('off')\n",
        "                \n",
        "                # Guardar imagen con detecciones\n",
        "                imagen_guardada = resultados_dir / f\"deteccion_{timestamp}_{i+1}_{img_path.stem}.jpg\"\n",
        "                cv2.imwrite(str(imagen_guardada), annotated)\n",
        "                \n",
        "                # Recopilar informaci√≥n de detecciones\n",
        "                imagen_info = {\n",
        "                    'imagen_original': img_path.name,\n",
        "                    'imagen_resultado': imagen_guardada.name,\n",
        "                    'detecciones': []\n",
        "                }\n",
        "                \n",
        "                # Mostrar detecciones en texto\n",
        "                if results[0].boxes is not None and len(results[0].boxes) > 0:\n",
        "                    detections = []\n",
        "                    for box in results[0].boxes:\n",
        "                        cls = int(box.cls[0])\n",
        "                        conf = float(box.conf[0])\n",
        "                        class_name = model.names[cls]\n",
        "                        detections.append(f\"{class_name}: {conf:.2f}\")\n",
        "                        \n",
        "                        # Guardar coordenadas de la caja\n",
        "                        xyxy = box.xyxy[0].tolist()  # [x1, y1, x2, y2]\n",
        "                        imagen_info['detecciones'].append({\n",
        "                            'clase': class_name,\n",
        "                            'confianza': round(conf, 3),\n",
        "                            'coordenadas': [round(x, 1) for x in xyxy]\n",
        "                        })\n",
        "                    \n",
        "                    det_text = \"\\n\".join(detections)\n",
        "                    plt.text(0.02, 0.98, det_text, transform=plt.gca().transAxes,\n",
        "                            verticalalignment='top', \n",
        "                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "                else:\n",
        "                    plt.text(0.02, 0.98, \"Sin detecciones\", transform=plt.gca().transAxes,\n",
        "                            verticalalignment='top', \n",
        "                            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
        "                    imagen_info['detecciones'] = []\n",
        "                \n",
        "                detecciones_info.append(imagen_info)\n",
        "                            \n",
        "            except Exception as e:\n",
        "                plt.text(0.5, 0.5, f\"Error: {str(e)}\", transform=plt.gca().transAxes,\n",
        "                        ha='center', va='center',\n",
        "                        bbox=dict(boxstyle='round', facecolor='red', alpha=0.8))\n",
        "                plt.title(f\"Error: {img_path.name}\")\n",
        "                plt.axis('off')\n",
        "        \n",
        "        # Guardar el gr√°fico completo\n",
        "        grafico_guardado = resultados_dir / f\"resumen_pruebas_{timestamp}.png\"\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(str(grafico_guardado), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Guardar informaci√≥n detallada en JSON\n",
        "        import json\n",
        "        info_guardada = resultados_dir / f\"detecciones_{timestamp}.json\"\n",
        "        with open(info_guardada, 'w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'timestamp': timestamp,\n",
        "                'modelo_usado': str(best_model_path),\n",
        "                'configuracion': {'conf': 0.25, 'iou': 0.45},\n",
        "                'resultados': detecciones_info\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        # Crear reporte en texto\n",
        "        reporte_guardado = resultados_dir / f\"reporte_{timestamp}.txt\"\n",
        "        with open(reporte_guardado, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"REPORTE DE PRUEBAS - {timestamp}\\n\")\n",
        "            f.write(\"=\"*50 + \"\\n\\n\")\n",
        "            f.write(f\"Modelo usado: {best_model_path}\\n\")\n",
        "            f.write(f\"Configuraci√≥n: conf=0.25, iou=0.45\\n\")\n",
        "            f.write(f\"Im√°genes probadas: {len(detecciones_info)}\\n\\n\")\n",
        "            \n",
        "            for i, info in enumerate(detecciones_info, 1):\n",
        "                f.write(f\"IMAGEN {i}: {info['imagen_original']}\\n\")\n",
        "                f.write(f\"Resultado guardado: {info['imagen_resultado']}\\n\")\n",
        "                if info['detecciones']:\n",
        "                    f.write(f\"Detecciones encontradas: {len(info['detecciones'])}\\n\")\n",
        "                    for det in info['detecciones']:\n",
        "                        f.write(f\"  - {det['clase']}: {det['confianza']:.3f} \"\n",
        "                               f\"[{', '.join(map(str, det['coordenadas']))}]\\n\")\n",
        "                else:\n",
        "                    f.write(\"Sin detecciones\\n\")\n",
        "                f.write(\"\\n\")\n",
        "        \n",
        "        print(f\"\\nüíæ RESULTADOS GUARDADOS:\")\n",
        "        print(f\"üìÅ Carpeta: {resultados_dir}/\")\n",
        "        print(f\"üìä Gr√°fico resumen: {grafico_guardado.name}\")\n",
        "        print(f\"üìÑ Reporte detallado: {reporte_guardado.name}\")\n",
        "        print(f\"üìã Datos JSON: {info_guardada.name}\")\n",
        "        print(f\"üñºÔ∏è  Im√°genes individuales: {len(detecciones_info)} archivos\")\n",
        "        print(f\"‚úÖ Pruebas completadas con {num_muestras} im√°genes\")\n",
        "        \n",
        "        return detecciones_info\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el modelo: {e}\")\n",
        "        return None\n",
        "\n",
        "# Ejecutar pruebas\n",
        "resultados_pruebas = probar_modelo_con_muestras()\n",
        "\n",
        "\n",
        "# FUNCI√ìN AUXILIAR: Verificar estructura de carpetas\n",
        "\n",
        "def verificar_estructura():\n",
        "    \"\"\"Verificar la estructura de carpetas y archivos\"\"\"\n",
        "    print(\"üîç VERIFICACI√ìN DE ESTRUCTURA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Verificar runs/detect\n",
        "    runs_dir = Path('runs/detect')\n",
        "    if runs_dir.exists():\n",
        "        print(f\"üìÅ {runs_dir}/\")\n",
        "        for carpeta in sorted(runs_dir.iterdir()):\n",
        "            if carpeta.is_dir():\n",
        "                print(f\"  ‚îú‚îÄ‚îÄ {carpeta.name}/\")\n",
        "                \n",
        "                # Verificar weights\n",
        "                weights_dir = carpeta / 'weights'\n",
        "                if weights_dir.exists():\n",
        "                    archivos_pt = list(weights_dir.glob('*.pt'))\n",
        "                    if archivos_pt:\n",
        "                        print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ weights/\")\n",
        "                        for archivo in archivos_pt:\n",
        "                            print(f\"  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {archivo.name}\")\n",
        "                    else:\n",
        "                        print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ weights/ (sin archivos .pt)\")\n",
        "                else:\n",
        "                    print(f\"  ‚îÇ   ‚îî‚îÄ‚îÄ (sin carpeta weights)\")\n",
        "                \n",
        "                # Verificar otros archivos importantes\n",
        "                archivos_importantes = ['results.png', 'confusion_matrix.png', 'val_batch0_pred.jpg']\n",
        "                for archivo in archivos_importantes:\n",
        "                    if (carpeta / archivo).exists():\n",
        "                        print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ {archivo}\")\n",
        "    else:\n",
        "        print(\"‚ùå No existe la carpeta runs/detect\")\n",
        "    \n",
        "    # Verificar dataset\n",
        "    print(f\"\\nüìÅ dataset/\")\n",
        "    dataset_dir = Path('dataset')\n",
        "    if dataset_dir.exists():\n",
        "        for subdir in ['train', 'valid', 'val', 'test']:\n",
        "            subdir_path = dataset_dir / subdir\n",
        "            if subdir_path.exists():\n",
        "                images_path = subdir_path / 'images'\n",
        "                labels_path = subdir_path / 'labels'\n",
        "                \n",
        "                num_images = len(list(images_path.glob('*'))) if images_path.exists() else 0\n",
        "                num_labels = len(list(labels_path.glob('*'))) if labels_path.exists() else 0\n",
        "                \n",
        "                print(f\"  ‚îú‚îÄ‚îÄ {subdir}/ ({num_images} imgs, {num_labels} labels)\")\n",
        "\n",
        "# Ejecutar verificaci√≥n (comentar si no necesitas)\n",
        "# verificar_estructura()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "nOX6BlCIUgNK",
        "outputId": "fc6931c8-10a9-4218-d1be-191b6182164f"
      },
      "outputs": [],
      "source": [
        "# CELDA 10: Continuar entrenamiento desde last.pt\n",
        "\n",
        "def encontrar_last_modelo():\n",
        "    \"\"\"Buscar el modelo last.pt m√°s reciente\"\"\"\n",
        "    runs_dir = Path('runs/detect')\n",
        "    posibles_rutas = []\n",
        "    \n",
        "    if runs_dir.exists():\n",
        "        for carpeta in runs_dir.iterdir():\n",
        "            if carpeta.is_dir():\n",
        "                # Buscar last.pt en weights/\n",
        "                ruta_weights = carpeta / 'weights' / 'last.pt'\n",
        "                if ruta_weights.exists():\n",
        "                    posibles_rutas.append((ruta_weights, carpeta.stat().st_mtime))\n",
        "                \n",
        "                # Tambi√©n buscar directamente en la carpeta\n",
        "                ruta_directa = carpeta / 'last.pt'\n",
        "                if ruta_directa.exists():\n",
        "                    posibles_rutas.append((ruta_directa, carpeta.stat().st_mtime))\n",
        "    \n",
        "    if posibles_rutas:\n",
        "        # Ordenar por fecha de modificaci√≥n (m√°s reciente primero)\n",
        "        posibles_rutas.sort(key=lambda x: x[1], reverse=True)\n",
        "        return posibles_rutas[0][0]\n",
        "    \n",
        "    return None\n",
        "\n",
        "def continuar_entrenamiento(epochs_adicionales=50, nuevo_lr=None, nuevo_batch_size=None):\n",
        "    \"\"\"\n",
        "    Continuar el entrenamiento desde el √∫ltimo checkpoint (last.pt)\n",
        "    \n",
        "    Args:\n",
        "        epochs_adicionales (int): N√∫mero de √©pocas adicionales\n",
        "        nuevo_lr (float): Nueva tasa de aprendizaje (opcional)\n",
        "        nuevo_batch_size (int): Nuevo tama√±o de batch (opcional)\n",
        "    \"\"\"\n",
        "    print(\"üîÑ CONTINUANDO ENTRENAMIENTO\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Buscar el modelo last.pt\n",
        "    last_model_path = encontrar_last_modelo()\n",
        "    \n",
        "    if last_model_path is None:\n",
        "        print(\"‚ùå No se encuentra ning√∫n modelo last.pt\")\n",
        "        print(\"üí° Aseg√∫rate de haber entrenado un modelo anteriormente\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"‚úÖ Modelo encontrado: {last_model_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Cargar el modelo desde el checkpoint\n",
        "        model = YOLO(str(last_model_path))\n",
        "        \n",
        "        # Preparar par√°metros de entrenamiento\n",
        "        train_params = {\n",
        "            'data': 'data.yaml',\n",
        "            'epochs': epochs_adicionales,\n",
        "            'patience': 20,\n",
        "            'save_period': 5,\n",
        "            'verbose': True,\n",
        "            'plots': True\n",
        "        }\n",
        "        \n",
        "        # Agregar par√°metros opcionales si se proporcionan\n",
        "        if nuevo_lr is not None:\n",
        "            train_params['lr0'] = nuevo_lr\n",
        "            print(f\"üìà Usando nueva tasa de aprendizaje: {nuevo_lr}\")\n",
        "        \n",
        "        if nuevo_batch_size is not None:\n",
        "            train_params['batch'] = nuevo_batch_size\n",
        "            print(f\"üì¶ Usando nuevo tama√±o de batch: {nuevo_batch_size}\")\n",
        "        \n",
        "        print(f\"üéØ √âpocas adicionales: {epochs_adicionales}\")\n",
        "        print(f\"üìä Iniciando entrenamiento continuo...\")\n",
        "        print(\"‚è±Ô∏è  Esto puede tomar varios minutos dependiendo del hardware...\")\n",
        "        \n",
        "        # Continuar entrenamiento\n",
        "        results = model.train(**train_params)\n",
        "        \n",
        "        print(\"\\n‚úÖ ENTRENAMIENTO CONTINUO COMPLETADO\")\n",
        "        print(\"=\" * 40)\n",
        "        \n",
        "        # Mostrar informaci√≥n del nuevo entrenamiento\n",
        "        runs_dir = Path('runs/detect')\n",
        "        model_dirs = [d for d in runs_dir.iterdir() if d.is_dir()]\n",
        "        if model_dirs:\n",
        "            latest_dir = max(model_dirs, key=lambda x: x.stat().st_mtime)\n",
        "            print(f\"üìÅ Nuevo modelo guardado en: {latest_dir}\")\n",
        "            \n",
        "            # Verificar archivos generados\n",
        "            best_path = latest_dir / 'weights' / 'best.pt'\n",
        "            last_path = latest_dir / 'weights' / 'last.pt'\n",
        "            \n",
        "            if best_path.exists():\n",
        "                print(f\"üèÜ Mejor modelo: {best_path}\")\n",
        "            if last_path.exists():\n",
        "                print(f\"üîÑ √öltimo checkpoint: {last_path}\")\n",
        "            \n",
        "            # EVALUAR EL NUEVO MODELO Y MOSTRAR M√âTRICAS\n",
        "            if best_path.exists():\n",
        "                try:\n",
        "                    print(f\"\\nüìä EVALUANDO NUEVO MODELO...\")\n",
        "                    nuevo_model = YOLO(str(best_path))\n",
        "                    nuevo_metrics = nuevo_model.val()\n",
        "                    \n",
        "                    print(f\"\\nüìà M√âTRICAS DEL MODELO CONTINUADO:\")\n",
        "                    print(f\"mAP50: {nuevo_metrics.box.map50:.3f}\")\n",
        "                    print(f\"mAP50-95: {nuevo_metrics.box.map:.3f}\")\n",
        "                    print(f\"Precision: {nuevo_metrics.box.mp:.3f}\")\n",
        "                    print(f\"Recall: {nuevo_metrics.box.mr:.3f}\")\n",
        "                    \n",
        "                    # Comparar con modelo anterior si tenemos las m√©tricas\n",
        "                    print(f\"\\nüìä COMPARACI√ìN CON ENTRENAMIENTO ANTERIOR:\")\n",
        "                    print(f\"{'M√©trica':<12} {'Anterior':<10} {'Nuevo':<10} {'Mejora':<10}\")\n",
        "                    print(\"-\" * 45)\n",
        "                    \n",
        "                    # Nota: Como no tenemos las m√©tricas anteriores aqu√≠,\n",
        "                    # al menos mostramos las nuevas de forma clara\n",
        "                    print(f\"{'mAP50':<12} {'N/A':<10} {nuevo_metrics.box.map50:.3f:<10} {'+':<10}\")\n",
        "                    print(f\"{'mAP50-95':<12} {'N/A':<10} {nuevo_metrics.box.map:.3f:<10} {'+':<10}\")\n",
        "                    print(f\"{'Precision':<12} {'N/A':<10} {nuevo_metrics.box.mp:.3f:<10} {'+':<10}\")\n",
        "                    print(f\"{'Recall':<12} {'N/A':<10} {nuevo_metrics.box.mr:.3f:<10} {'+':<10}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è  No se pudo evaluar el modelo: {e}\")\n",
        "            \n",
        "            # Mostrar curvas de entrenamiento si existen\n",
        "            results_png = latest_dir / 'results.png'\n",
        "            if results_png.exists():\n",
        "                print(f\"\\nüìä NUEVAS CURVAS DE ENTRENAMIENTO:\")\n",
        "                display(Image(str(results_png)))\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  No se encontr√≥ results.png en {latest_dir}\")\n",
        "        \n",
        "        return model, results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error durante el entrenamiento continuo: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def configurar_entrenamiento_continuo():\n",
        "    \"\"\"Configurar y ejecutar entrenamiento continuo con opciones\"\"\"\n",
        "    print(\"‚öôÔ∏è  CONFIGURACI√ìN DE ENTRENAMIENTO CONTINUO\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Mostrar modelos disponibles\n",
        "    last_model_path = encontrar_last_modelo()\n",
        "    if last_model_path:\n",
        "        print(f\"‚úÖ Modelo base encontrado: {last_model_path}\")\n",
        "        \n",
        "        # Informaci√≥n del modelo\n",
        "        try:\n",
        "            model_info = YOLO(str(last_model_path))\n",
        "            print(f\"üìã Informaci√≥n del modelo:\")\n",
        "            print(f\"   - Arquitectura: {last_model_path.parent.parent.name}\")\n",
        "            print(f\"   - √öltima modificaci√≥n: {datetime.fromtimestamp(last_model_path.stat().st_mtime)}\")\n",
        "        except:\n",
        "            pass\n",
        "    else:\n",
        "        print(\"‚ùå No se encuentra modelo base (last.pt)\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\nüéõÔ∏è  OPCIONES DE CONFIGURACI√ìN:\")\n",
        "    print(\"Puedes ajustar estos par√°metros seg√∫n tus necesidades:\")\n",
        "    print(\"- epochs_adicionales: N√∫mero de √©pocas extra (default: 50)\")\n",
        "    print(\"- nuevo_lr: Nueva tasa de aprendizaje (default: mantener actual)\")\n",
        "    print(\"- nuevo_batch_size: Nuevo tama√±o de batch (default: mantener actual)\")\n",
        "    \n",
        "    print(\"\\nüìù EJEMPLOS DE USO:\")\n",
        "    print(\"# Entrenamiento b√°sico (50 √©pocas adicionales)\")\n",
        "    print(\"modelo_continuado, resultados = continuar_entrenamiento()\")\n",
        "    print(\"\")\n",
        "    print(\"# Entrenamiento con par√°metros personalizados\")\n",
        "    print(\"modelo_continuado, resultados = continuar_entrenamiento(\")\n",
        "    print(\"    epochs_adicionales=100,\")\n",
        "    print(\"    nuevo_lr=0.001,\")\n",
        "    print(\"    nuevo_batch_size=8\")\n",
        "    print(\")\")\n",
        "    \n",
        "    return last_model_path\n",
        "\n",
        "# Configurar entrenamiento continuo\n",
        "modelo_base = configurar_entrenamiento_continuo()\n",
        "\n",
        "\n",
        "# EJECUTAR ENTRENAMIENTO CONTINUO\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ INICIANDO ENTRENAMIENTO CONTINUO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ejecutar entrenamiento continuo con par√°metros b√°sicos\n",
        "modelo_continuado, resultados = continuar_entrenamiento(\n",
        "    epochs_adicionales=100,  # Cambia este n√∫mero seg√∫n necesites\n",
        "    nuevo_lr=0.02,          # CON NONE Mantiene el learning rate actual\n",
        "    nuevo_batch_size=32   # CON NONE Mantiene el batch size actual\n",
        ")\n",
        "\n",
        "# Si quieres usar par√°metros personalizados, descomenta y modifica esta opci√≥n:\n",
        "# modelo_continuado, resultados = continuar_entrenamiento(\n",
        "#     epochs_adicionales=20,\n",
        "#     nuevo_lr=0.0005,      # Learning rate m√°s bajo para fine-tuning\n",
        "#     nuevo_batch_size=8    # Batch size diferente\n",
        "# )\n",
        "\n",
        "\n",
        "# OPCIONES ADICIONALES (descomenta la que necesites)\n",
        "\n",
        "\n",
        "# OPCI√ìN 1: Entrenamiento corto para probar\n",
        "# modelo_continuado, resultados = continuar_entrenamiento(epochs_adicionales=5)\n",
        "\n",
        "# OPCI√ìN 2: Entrenamiento largo\n",
        "# modelo_continuado, resultados = continuar_entrenamiento(epochs_adicionales=50)\n",
        "\n",
        "# OPCI√ìN 3: Fine-tuning (learning rate m√°s bajo)\n",
        "# modelo_continuado, resultados = continuar_entrenamiento(\n",
        "#     epochs_adicionales=25,\n",
        "#     nuevo_lr=0.0001\n",
        "# )\n",
        "\n",
        "# OPCI√ìN 4: Cambiar batch size para memoria limitada\n",
        "# modelo_continuado, resultados = continuar_entrenamiento(\n",
        "#     epochs_adicionales=15,\n",
        "#     nuevo_batch_size=4\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_2lOiHcU9Wo",
        "outputId": "8dc091b0-8c1a-4148-e2ec-1ed08ab67599"
      },
      "outputs": [],
      "source": [
        "# CELDA 11: Informaci√≥n final y pr√≥ximos pasos\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üèÅ ENTRENAMIENTO COMPLETADO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìã RESUMEN:\")\n",
        "print(\"‚úÖ Modelo entrenado con transfer learning\")\n",
        "print(\"‚úÖ Evaluaci√≥n completada\")\n",
        "print(\"‚úÖ Pruebas visuales realizadas\")\n",
        "\n",
        "print(\"\\nüîÑ PR√ìXIMOS PASOS:\")\n",
        "print(\"1. Revisar m√©tricas de validaci√≥n: mAP50 > 0.9 es bueno, mAP50-95 > 0.7 es excelente\")\n",
        "print(\"2. Descargar el √∫ltimo best.pt para usar en producci√≥n\")\n",
        "print(\"3. Si los resultados no son satisfactorios:\")\n",
        "print(\"   - Probar con modelo m√°s grande (s, m, l, x)\")\n",
        "print(\"   - Aumentar n√∫mero de √©pocas\")\n",
        "print(\"   - Aumentar batch_size si la GPU lo permite\")\n",
        "print(\"   - Bajar learning rate para fine-tuning\")\n",
        "print(\"   - Aumentar tama√±o de imagen img_size\")\n",
        "print(\"   - modificar patience\")\n",
        "\n",
        "print(\"\\nüí° CONSEJOS:\")\n",
        "print(\"- El archivo 'best.pt' es tu modelo final\")\n",
        "print(\"- Usa conf=0.25 como threshold inicial\")\n",
        "print(\"- Para producci√≥n, ajusta conf seg√∫n tus necesidades\")\n",
        "print(\"- El modelo funciona mejor con im√°genes similares al dataset\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
